{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8zHClUgcyMxiVrlSsEuyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtthebot1/projects/blob/main/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOPtErBFqjA6"
      },
      "outputs": [],
      "source": [
        "#Install livelossplot dependency\n",
        "!pip install livelossplot==0.3.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required packages\n",
        "from torchvision.models.alexnet import AlexNet\n",
        "from torchvision.transforms.transforms import Resize\n",
        "import torch\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision.models as models\n",
        "AlexNet = models.AlexNet()\n",
        "\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Simple convolutional neural network (AlexNet)\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Normalization of images theough flips horizontally and random crops, and RBG pixel value\n",
        "# normalization \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Get the CIFAR training data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=256,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          drop_last=True)\n",
        "\n",
        "test_and_val_set = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform_test)\n",
        "\n",
        "# Splitting dataset into valset and test set.\n",
        "indices = np.arange(len(test_and_val_set))\n",
        "val_set = Subset(test_and_val_set, indices[:5000])\n",
        "test_set = Subset(test_and_val_set, indices[5000:])\n",
        "\n",
        "val_set_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "test_set_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define a loss function which is cross entropy\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "\n",
        "# Define our network, put it on GPU and set it up into a training mode.\n",
        "net = AlexNet()\n",
        "net = net.cuda()\n",
        "net.train()\n",
        "\n",
        "# Define optimizer and learning rate.\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.06, momentum=0.9)\n",
        "\n",
        "# Define a validation function which will be run after each epoch to\n",
        "# see if accuracy of our model improved or worsened.\n",
        "def validate():\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    counter = 0\n",
        "    correctly_predicted_counter = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_set_loader):\n",
        "\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            _, predicted_classes = outputs.max(1)\n",
        "\n",
        "            counter += targets.size(0)\n",
        "            correctly_predicted_counter += (predicted_classes == targets).sum().item()\n",
        "    \n",
        "    accuracy = float(correctly_predicted_counter) / counter\n",
        "    \n",
        "    predicted_classes_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_set_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = net(inputs)\n",
        "            _, predicted_classes = outputs.max(1)\n",
        "            predicted_classes_list += list(map(lambda x: str(x), predicted_classes.cpu().detach().numpy().tolist()))\n",
        "\n",
        "    predicted_classes_list = list(enumerate(predicted_classes_list))\n",
        "    \n",
        "    net.train()\n",
        "    \n",
        "    return accuracy, predicted_classes_list"
      ],
      "metadata": {
        "id": "ey259rPhq_Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "best_accuracy = 0.0\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "for epoch_number in range(100):\n",
        "    \n",
        "    train_loss_list = []\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_list.append(loss.data.item())\n",
        "    \n",
        "    if epoch_number == 20:\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "\n",
        "            param_group['lr'] = 0.01\n",
        "\n",
        "    if epoch_number == 40:\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "\n",
        "            param_group['lr'] = 0.001\n",
        "        \n",
        "        \n",
        "        \n",
        "    current_accuracy, predicted_classes_list = validate()\n",
        "\n",
        "    liveloss.update({'Average Training Batch Loss': sum(train_loss_list) / len(train_loss_list),\n",
        "                     'Validation Accuracy': current_accuracy})\n",
        "    liveloss.draw()\n",
        "\n",
        "    if current_accuracy > best_accuracy:\n",
        "\n",
        "        print(current_accuracy)\n",
        "        best_accuracy = current_accuracy\n",
        "        torch.save(net.state_dict(), 'resnet_20_cifar10_kaggle.pth')\n",
        "        \n",
        "        # Saving best predictions so far\n",
        "        submission_df = pd.DataFrame(predicted_classes_list, columns = ['Id', 'Category'])\n",
        "        submission_df = submission_df['Category']\n",
        "        submission_df = submission_df.replace(0)\n",
        "        submission_df = pd.DataFrame(submission_df)\n",
        "        submission_df['Id'] = submission_df.index\n",
        "        submission_df = submission_df[['Id', 'Category']]\n",
        "        submission_df.to_csv('cifar_10_best_submission.csv', index=False)\n",
        "        \n",
        "end = time.time()\n",
        "print(end - start)\n",
        "\n",
        "# Plot below"
      ],
      "metadata": {
        "id": "r67LsvPurdvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}